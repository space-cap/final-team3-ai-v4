"""
í…œí”Œë¦¿ ìƒì„± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ API ìš”ì²­ì„ í†µí•´ ë‹¨ê³„ë³„ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³  ë³‘ëª© ì§€ì ì„ ì‹ë³„í•©ë‹ˆë‹¤.
"""
import time
import json
import requests
import statistics
from datetime import datetime
from typing import List, Dict, Any
import asyncio
import aiohttp

# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì •ì˜
TEST_CASES = [
    {
        "name": "ê°„ë‹¨í•œ_êµìœ¡_í…œí”Œë¦¿",
        "request": {
            "user_request": "ì˜¨ë¼ì¸ ê°•ì˜ ìˆ˜ê°• ì‹ ì²­ì´ ì™„ë£Œë˜ì—ˆìŒì„ ì•Œë¦¬ëŠ” ë©”ì‹œì§€",
            "business_type": "êµìœ¡",
            "service_type": "ì‹ ì²­",
            "target_audience": "ìˆ˜ê°•ìƒ",
            "tone": "ì •ì¤‘í•œ",
            "required_variables": ["ìˆ˜ì‹ ìëª…", "ê°•ì˜ëª…"],
            "additional_requirements": "ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ"
        }
    },
    {
        "name": "ë³µì¡í•œ_ì˜ë£Œ_í…œí”Œë¦¿",
        "request": {
            "user_request": "ë³‘ì› ì˜ˆì•½ í™•ì¸ ë° ì§„ë£Œ ì „ ì¤€ë¹„ì‚¬í•­, ì£¼ì˜ì‚¬í•­, ìœ„ì¹˜ ì•ˆë‚´ë¥¼ í¬í•¨í•œ ìƒì„¸í•œ ë©”ì‹œì§€",
            "business_type": "ì˜ë£Œ",
            "service_type": "ì˜ˆì•½",
            "target_audience": "í™˜ì",
            "tone": "ì¹œê·¼í•œ",
            "required_variables": ["í™˜ìëª…", "ì§„ë£Œê³¼", "ì˜ˆì•½ì¼ì‹œ", "ë‹´ë‹¹ì˜", "ë³‘ì›ì£¼ì†Œ"],
            "additional_requirements": "ì§„ë£Œ ì „ ì¤€ë¹„ì‚¬í•­ê³¼ ì£¼ì˜ì‚¬í•­ í¬í•¨, ë²„íŠ¼ ì¶”ê°€ í•„ìš”"
        }
    },
    {
        "name": "ì‡¼í•‘ëª°_ì£¼ë¬¸_í…œí”Œë¦¿",
        "request": {
            "user_request": "ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ì£¼ë¬¸ ì™„ë£Œ í›„ ë°°ì†¡ ì •ë³´ì™€ êµí™˜/í™˜ë¶ˆ ì •ì±…ì„ ì•ˆë‚´í•˜ëŠ” ë©”ì‹œì§€",
            "business_type": "ì‡¼í•‘ëª°",
            "service_type": "ì£¼ë¬¸",
            "target_audience": "ê³ ê°",
            "tone": "ì¹œê·¼í•œ",
            "required_variables": ["ê³ ê°ëª…", "ì£¼ë¬¸ë²ˆí˜¸", "ìƒí’ˆëª…", "ë°°ì†¡ì£¼ì†Œ"],
            "additional_requirements": "êµí™˜/í™˜ë¶ˆ ì •ì±… í¬í•¨"
        }
    },
    {
        "name": "ê¸ˆìœµ_ì„œë¹„ìŠ¤_í…œí”Œë¦¿",
        "request": {
            "user_request": "ëŒ€ì¶œ ì‹ ì²­ ìŠ¹ì¸ ê²°ê³¼ì™€ ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´ë¥¼ í¬í•¨í•œ ë©”ì‹œì§€",
            "business_type": "ê¸ˆìœµ",
            "service_type": "ì‹ ì²­",
            "target_audience": "ê³ ê°",
            "tone": "ì •ì¤‘í•œ",
            "required_variables": ["ê³ ê°ëª…", "ëŒ€ì¶œìƒí’ˆëª…", "ìŠ¹ì¸ê¸ˆì•¡", "ê¸ˆë¦¬"],
            "additional_requirements": "ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´ í¬í•¨"
        }
    },
    {
        "name": "ìŒì‹ì _ì˜ˆì•½_í…œí”Œë¦¿",
        "request": {
            "user_request": "ë ˆìŠ¤í† ë‘ ì˜ˆì•½ í™•ì¸ ë° ë°©ë¬¸ ì‹œ ì£¼ì˜ì‚¬í•­ ì•ˆë‚´ ë©”ì‹œì§€",
            "business_type": "ìŒì‹ì ",
            "service_type": "ì˜ˆì•½",
            "target_audience": "ê³ ê°",
            "tone": "ì¹œê·¼í•œ",
            "required_variables": ["ê³ ê°ëª…", "ì˜ˆì•½ì¼ì‹œ", "ì¸ì›ìˆ˜", "ë§¤ì¥ëª…"],
            "additional_requirements": "ì£¼ì°¨ ì •ë³´ ë° ë°©ë¬¸ ì‹œ ì£¼ì˜ì‚¬í•­ í¬í•¨"
        }
    }
]

class PerformanceTestRunner:
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°"""

    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.api_endpoint = f"{base_url}/api/v1/templates/generate"
        self.results = []

    def run_single_test(self, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰"""
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘: {test_case['name']}")

        start_time = time.time()

        try:
            response = requests.post(
                self.api_endpoint,
                json=test_case['request'],
                headers={'Content-Type': 'application/json'},
                timeout=120  # 2ë¶„ íƒ€ì„ì•„ì›ƒ
            )

            end_time = time.time()
            total_time = end_time - start_time

            if response.status_code == 200:
                result_data = response.json()

                # ì„±ëŠ¥ ë°ì´í„° ì¶”ì¶œ
                performance_data = result_data.get('performance', {})

                return {
                    'test_name': test_case['name'],
                    'success': True,
                    'total_time': total_time,
                    'status_code': response.status_code,
                    'template_length': len(result_data.get('template', {}).get('text', '')),
                    'compliance_score': result_data.get('compliance', {}).get('score', 0),
                    'iterations': result_data.get('workflow_info', {}).get('iterations', 0),
                    'performance_data': performance_data,
                    'step_timings': performance_data.get('step_timings', []),
                    'bottlenecks': performance_data.get('bottlenecks', []),
                    'recommendations': performance_data.get('recommendations', [])
                }
            else:
                return {
                    'test_name': test_case['name'],
                    'success': False,
                    'total_time': total_time,
                    'status_code': response.status_code,
                    'error': response.text
                }

        except Exception as e:
            end_time = time.time()
            return {
                'test_name': test_case['name'],
                'success': False,
                'total_time': end_time - start_time,
                'error': str(e)
            }

    def run_all_tests(self, iterations: int = 3) -> List[Dict[str, Any]]:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰"""
        print(f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘ - {len(TEST_CASES)}ê°œ ì¼€ì´ìŠ¤ x {iterations}íšŒ ë°˜ë³µ")

        all_results = []

        for i in range(iterations):
            print(f"\n=== ë°˜ë³µ {i+1}/{iterations} ===")

            for test_case in TEST_CASES:
                result = self.run_single_test(test_case)
                result['iteration'] = i + 1
                all_results.append(result)

                # ê°„ê²© ë‘ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
                time.sleep(2)

        self.results = all_results
        return all_results

    def analyze_results(self) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
        if not self.results:
            return {}

        # ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ë§Œ ë¶„ì„
        successful_results = [r for r in self.results if r.get('success', False)]

        if not successful_results:
            return {'error': 'No successful tests to analyze'}

        # ì „ì²´ í†µê³„
        total_times = [r['total_time'] for r in successful_results]

        analysis = {
            'test_summary': {
                'total_tests': len(self.results),
                'successful_tests': len(successful_results),
                'success_rate': len(successful_results) / len(self.results) * 100,
                'average_total_time': statistics.mean(total_times),
                'median_total_time': statistics.median(total_times),
                'max_total_time': max(total_times),
                'min_total_time': min(total_times),
                'std_dev_total_time': statistics.stdev(total_times) if len(total_times) > 1 else 0
            }
        }

        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë³„ ë¶„ì„
        analysis['by_test_case'] = {}
        for test_case in TEST_CASES:
            case_results = [r for r in successful_results if r['test_name'] == test_case['name']]
            if case_results:
                case_times = [r['total_time'] for r in case_results]
                analysis['by_test_case'][test_case['name']] = {
                    'avg_time': statistics.mean(case_times),
                    'min_time': min(case_times),
                    'max_time': max(case_times),
                    'avg_compliance_score': statistics.mean([r.get('compliance_score', 0) for r in case_results]),
                    'avg_iterations': statistics.mean([r.get('iterations', 0) for r in case_results])
                }

        # ë‹¨ê³„ë³„ ë¶„ì„
        step_analysis = {}
        for result in successful_results:
            step_timings = result.get('step_timings', [])
            for step in step_timings:
                step_name = step.get('step_name', 'unknown')
                duration = step.get('duration_seconds', 0)

                if step_name not in step_analysis:
                    step_analysis[step_name] = []
                step_analysis[step_name].append(duration)

        analysis['step_performance'] = {}
        for step_name, durations in step_analysis.items():
            if durations:
                analysis['step_performance'][step_name] = {
                    'avg_time': statistics.mean(durations),
                    'min_time': min(durations),
                    'max_time': max(durations),
                    'call_count': len(durations),
                    'total_time': sum(durations),
                    'percentage_of_total': 0  # ë‚˜ì¤‘ì— ê³„ì‚°
                }

        # ê° ë‹¨ê³„ì˜ ì „ì²´ ì‹œê°„ ëŒ€ë¹„ ë¹„ìœ¨ ê³„ì‚°
        total_step_time = sum(sum(durations) for durations in step_analysis.values())
        for step_name in analysis['step_performance']:
            step_total = analysis['step_performance'][step_name]['total_time']
            analysis['step_performance'][step_name]['percentage_of_total'] = (step_total / total_step_time * 100) if total_step_time > 0 else 0

        # ë³‘ëª© ì§€ì  ì‹ë³„
        bottlenecks = []
        for step_name, data in analysis['step_performance'].items():
            if data['percentage_of_total'] > 20:  # ì „ì²´ì˜ 20% ì´ìƒ
                bottlenecks.append({
                    'step_name': step_name,
                    'avg_time': data['avg_time'],
                    'percentage': data['percentage_of_total'],
                    'severity': 'high' if data['percentage_of_total'] > 40 else 'medium'
                })

        analysis['bottlenecks'] = sorted(bottlenecks, key=lambda x: x['percentage'], reverse=True)

        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = []

        # ì „ì²´ ì‹œê°„ì´ ê¸´ ê²½ìš°
        if analysis['test_summary']['average_total_time'] > 30:
            recommendations.append("í‰ê·  ì²˜ë¦¬ ì‹œê°„ì´ 30ì´ˆë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ì „ë°˜ì ì¸ ì„±ëŠ¥ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # íŠ¹ì • ë‹¨ê³„ê°€ ë³‘ëª©ì¸ ê²½ìš°
        for bottleneck in analysis['bottlenecks']:
            if bottleneck['step_name'] in ['template_generation', 'compliance_check']:
                recommendations.append(f"{bottleneck['step_name']} ë‹¨ê³„ê°€ {bottleneck['percentage']:.1f}%ì˜ ì‹œê°„ì„ ì°¨ì§€í•©ë‹ˆë‹¤. LLM í˜¸ì¶œ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
            elif bottleneck['step_name'] == 'policy_retrieval':
                recommendations.append(f"ì •ì±… ê²€ìƒ‰ì´ {bottleneck['percentage']:.1f}%ì˜ ì‹œê°„ì„ ì°¨ì§€í•©ë‹ˆë‹¤. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”ë‚˜ ìºì‹±ì„ ê³ ë ¤í•˜ì„¸ìš”.")

        # ì„±ê³µë¥ ì´ ë‚®ì€ ê²½ìš°
        if analysis['test_summary']['success_rate'] < 90:
            recommendations.append(f"ì„±ê³µë¥ ì´ {analysis['test_summary']['success_rate']:.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤. ì—ëŸ¬ ì²˜ë¦¬ ë° ì•ˆì •ì„± ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        analysis['recommendations'] = recommendations

        return analysis

    def generate_report(self) -> str:
        """ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        analysis = self.analyze_results()

        if 'error' in analysis:
            return f"ë¶„ì„ ì‹¤íŒ¨: {analysis['error']}"

        report = []
        report.append("=" * 80)
        report.append("í…œí”Œë¦¿ ìƒì„± ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œ")
        report.append("=" * 80)
        report.append(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")

        # ì „ì²´ ìš”ì•½
        summary = analysis['test_summary']
        report.append("ğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ìš”ì•½")
        report.append("-" * 50)
        report.append(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {summary['total_tests']}")
        report.append(f"ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {summary['successful_tests']}")
        report.append(f"ì„±ê³µë¥ : {summary['success_rate']:.1f}%")
        report.append(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {summary['average_total_time']:.2f}ì´ˆ")
        report.append(f"ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„: {summary['max_total_time']:.2f}ì´ˆ")
        report.append(f"ìµœì†Œ ì²˜ë¦¬ ì‹œê°„: {summary['min_total_time']:.2f}ì´ˆ")
        report.append(f"í‘œì¤€í¸ì°¨: {summary['std_dev_total_time']:.2f}ì´ˆ")
        report.append("")

        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë³„ ì„±ëŠ¥
        report.append("ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë³„ ì„±ëŠ¥")
        report.append("-" * 50)
        for test_name, data in analysis['by_test_case'].items():
            report.append(f"â€¢ {test_name}")
            report.append(f"  í‰ê·  ì‹œê°„: {data['avg_time']:.2f}ì´ˆ")
            report.append(f"  ë²”ìœ„: {data['min_time']:.2f}ì´ˆ ~ {data['max_time']:.2f}ì´ˆ")
            report.append(f"  í‰ê·  ì»´í”Œë¼ì´ì–¸ìŠ¤ ì ìˆ˜: {data['avg_compliance_score']:.1f}")
            report.append(f"  í‰ê·  ë°˜ë³µ íšŸìˆ˜: {data['avg_iterations']:.1f}")
            report.append("")

        # ë‹¨ê³„ë³„ ì„±ëŠ¥
        report.append("âš¡ ë‹¨ê³„ë³„ ì„±ëŠ¥ ë¶„ì„")
        report.append("-" * 50)
        step_perf = analysis['step_performance']
        sorted_steps = sorted(step_perf.items(), key=lambda x: x[1]['percentage_of_total'], reverse=True)

        for step_name, data in sorted_steps:
            report.append(f"â€¢ {step_name}")
            report.append(f"  í‰ê·  ì‹œê°„: {data['avg_time']:.3f}ì´ˆ")
            report.append(f"  ì „ì²´ ëŒ€ë¹„: {data['percentage_of_total']:.1f}%")
            report.append(f"  í˜¸ì¶œ íšŸìˆ˜: {data['call_count']}")
            report.append(f"  ë²”ìœ„: {data['min_time']:.3f}ì´ˆ ~ {data['max_time']:.3f}ì´ˆ")
            report.append("")

        # ë³‘ëª© ì§€ì 
        if analysis['bottlenecks']:
            report.append("ğŸš« ì£¼ìš” ë³‘ëª© ì§€ì ")
            report.append("-" * 50)
            for bottleneck in analysis['bottlenecks']:
                severity_emoji = "ğŸ”´" if bottleneck['severity'] == 'high' else "ğŸŸ¡"
                report.append(f"{severity_emoji} {bottleneck['step_name']}")
                report.append(f"  í‰ê·  ì‹œê°„: {bottleneck['avg_time']:.3f}ì´ˆ")
                report.append(f"  ì „ì²´ ëŒ€ë¹„: {bottleneck['percentage']:.1f}%")
                report.append("")

        # ê¶Œì¥ì‚¬í•­
        if analysis['recommendations']:
            report.append("ğŸ’¡ ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­")
            report.append("-" * 50)
            for i, rec in enumerate(analysis['recommendations'], 1):
                report.append(f"{i}. {rec}")
            report.append("")

        return "\n".join(report)

    def save_detailed_results(self, filename: str = None):
        """ìƒì„¸ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"performance_test_results_{timestamp}.json"

        analysis = self.analyze_results()

        output_data = {
            'metadata': {
                'test_date': datetime.now().isoformat(),
                'test_cases_count': len(TEST_CASES),
                'total_tests': len(self.results)
            },
            'raw_results': self.results,
            'analysis': analysis
        }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

        print(f"ìƒì„¸ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return filename

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ì¹´ì¹´ì˜¤ í…œí”Œë¦¿ ìƒì„± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # ì„œë²„ ìƒíƒœ í™•ì¸
    try:
        response = requests.get("http://localhost:8000/health", timeout=10)
        if response.status_code != 200:
            print("âŒ ì„œë²„ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì„œë²„ë¥¼ ë¨¼ì € ì‹œì‘í•´ì£¼ì„¸ìš”.")
            return
        print("âœ… ì„œë²„ ì—°ê²° í™•ì¸ë¨")
    except Exception as e:
        print(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        print("python run_server.py ëª…ë ¹ìœ¼ë¡œ ì„œë²„ë¥¼ ë¨¼ì € ì‹œì‘í•´ì£¼ì„¸ìš”.")
        return

    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_runner = PerformanceTestRunner()

    print(f"\ní…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:")
    for i, case in enumerate(TEST_CASES, 1):
        print(f"{i}. {case['name']} - {case['request']['business_type']}")

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = test_runner.run_all_tests(iterations=2)  # ê° ì¼€ì´ìŠ¤ë¥¼ 2íšŒì”© ì‹¤í–‰

    # ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80)

    report = test_runner.generate_report()
    print(report)

    # ìƒì„¸ ê²°ê³¼ ì €ì¥
    json_file = test_runner.save_detailed_results()

    print(f"\nâœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“„ ìƒì„¸ ê²°ê³¼: {json_file}")

if __name__ == "__main__":
    main()