"""
ìƒì„¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ - ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ë³‘ëª© ì§€ì  ì •í™•íˆ ì¸¡ì •
"""
import time
import json
import requests
import statistics
from typing import Dict, List

# ë‹¤ì–‘í•œ ë³µì¡ë„ì˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
DETAILED_TEST_CASES = [
    {
        "name": "ê°„ë‹¨í•œ_í…œí”Œë¦¿",
        "complexity": "low",
        "request": {
            "user_request": "ìˆ˜ê°• ì‹ ì²­ ì™„ë£Œ ì•ˆë‚´",
            "business_type": "êµìœ¡",
            "service_type": "ì‹ ì²­",
            "target_audience": "ìˆ˜ê°•ìƒ",
            "tone": "ì •ì¤‘í•œ",
            "required_variables": ["ìˆ˜ì‹ ìëª…", "ê°•ì˜ëª…"],
            "additional_requirements": "ê°„ë‹¨ëª…ë£Œí•˜ê²Œ"
        }
    },
    {
        "name": "ì¤‘ê°„_ë³µì¡ë„_í…œí”Œë¦¿",
        "complexity": "medium",
        "request": {
            "user_request": "ë³‘ì› ì˜ˆì•½ í™•ì¸ ë° ì¤€ë¹„ì‚¬í•­ ì•ˆë‚´ ë©”ì‹œì§€",
            "business_type": "ì˜ë£Œ",
            "service_type": "ì˜ˆì•½",
            "target_audience": "í™˜ì",
            "tone": "ì¹œê·¼í•œ",
            "required_variables": ["í™˜ìëª…", "ì§„ë£Œê³¼", "ì˜ˆì•½ì¼ì‹œ", "ë‹´ë‹¹ì˜"],
            "additional_requirements": "ì¤€ë¹„ì‚¬í•­ í¬í•¨"
        }
    },
    {
        "name": "ë³µì¡í•œ_í…œí”Œë¦¿",
        "complexity": "high",
        "request": {
            "user_request": "ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ì£¼ë¬¸ ì™„ë£Œ í›„ ë°°ì†¡ ì •ë³´, êµí™˜/í™˜ë¶ˆ ì •ì±…, ê³ ê°ì„¼í„° ì—°ë½ì²˜, ì ë¦½ê¸ˆ ì•ˆë‚´ë¥¼ í¬í•¨í•œ ìƒì„¸í•œ ë©”ì‹œì§€",
            "business_type": "ì‡¼í•‘ëª°",
            "service_type": "ì£¼ë¬¸",
            "target_audience": "ê³ ê°",
            "tone": "ì¹œê·¼í•œ",
            "required_variables": ["ê³ ê°ëª…", "ì£¼ë¬¸ë²ˆí˜¸", "ìƒí’ˆëª…", "ë°°ì†¡ì£¼ì†Œ", "ë°°ì†¡ì˜ˆì •ì¼", "ì ë¦½ê¸ˆ"],
            "additional_requirements": "êµí™˜/í™˜ë¶ˆ ì •ì±…, ê³ ê°ì„¼í„° ì •ë³´, ì ë¦½ê¸ˆ ìƒì„¸ ì•ˆë‚´ í¬í•¨"
        }
    }
]

def run_detailed_performance_test():
    """ìƒì„¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ìƒì„¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    results = {}

    for test_case in DETAILED_TEST_CASES:
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¤‘: {test_case['name']} ({test_case['complexity']} ë³µì¡ë„)")

        case_results = []

        # ê° ì¼€ì´ìŠ¤ë¥¼ 3íšŒì”© ì‹¤í–‰
        for i in range(3):
            print(f"  ë°˜ë³µ {i+1}/3...", end=" ")

            start_time = time.time()

            try:
                response = requests.post(
                    "http://localhost:8000/api/v1/templates/generate",
                    json=test_case['request'],
                    timeout=120
                )

                end_time = time.time()
                total_time = end_time - start_time

                if response.status_code == 200:
                    result_data = response.json()

                    case_result = {
                        'iteration': i + 1,
                        'success': True,
                        'total_time': total_time,
                        'template_length': len(result_data.get('template', {}).get('text', '')),
                        'compliance_score': result_data.get('compliance', {}).get('score', 0),
                        'iterations': result_data.get('workflow_info', {}).get('iterations', 0),
                        'has_performance_data': 'performance' in result_data
                    }

                    # ì„±ëŠ¥ ë°ì´í„° ì¶”ì¶œ ì‹œë„
                    if 'performance' in result_data:
                        perf_data = result_data['performance']
                        case_result['step_summary'] = perf_data.get('step_summary', {})
                        case_result['bottlenecks'] = perf_data.get('bottlenecks', [])

                    case_results.append(case_result)
                    print(f"âœ… {total_time:.1f}ì´ˆ")

                else:
                    print(f"âŒ HTTP {response.status_code}")
                    case_results.append({
                        'iteration': i + 1,
                        'success': False,
                        'error': f"HTTP {response.status_code}",
                        'total_time': total_time
                    })

            except Exception as e:
                end_time = time.time()
                print(f"âŒ {str(e)[:50]}...")
                case_results.append({
                    'iteration': i + 1,
                    'success': False,
                    'error': str(e),
                    'total_time': end_time - start_time
                })

            # ìš”ì²­ ê°„ ê°„ê²©
            time.sleep(1)

        results[test_case['name']] = {
            'complexity': test_case['complexity'],
            'results': case_results
        }

    return results

def analyze_detailed_results(results: Dict) -> Dict:
    """ìƒì„¸ ê²°ê³¼ ë¶„ì„"""
    analysis = {
        'summary': {},
        'by_complexity': {},
        'performance_trends': {},
        'recommendations': []
    }

    # ì „ì²´ ìš”ì•½
    all_successful = []
    for test_name, test_data in results.items():
        successful = [r for r in test_data['results'] if r.get('success', False)]
        all_successful.extend(successful)

    if all_successful:
        times = [r['total_time'] for r in all_successful]
        analysis['summary'] = {
            'total_tests': len(all_successful),
            'avg_time': statistics.mean(times),
            'median_time': statistics.median(times),
            'min_time': min(times),
            'max_time': max(times),
            'std_dev': statistics.stdev(times) if len(times) > 1 else 0
        }

    # ë³µì¡ë„ë³„ ë¶„ì„
    complexity_groups = {'low': [], 'medium': [], 'high': []}

    for test_name, test_data in results.items():
        complexity = test_data['complexity']
        successful = [r for r in test_data['results'] if r.get('success', False)]

        if successful:
            times = [r['total_time'] for r in successful]
            template_lengths = [r['template_length'] for r in successful]
            compliance_scores = [r['compliance_score'] for r in successful]

            complexity_groups[complexity].extend(times)

            analysis['by_complexity'][test_name] = {
                'complexity': complexity,
                'avg_time': statistics.mean(times),
                'avg_template_length': statistics.mean(template_lengths),
                'avg_compliance_score': statistics.mean(compliance_scores),
                'success_rate': len(successful) / len(test_data['results']) * 100
            }

    # ë³µì¡ë„ íŠ¸ë Œë“œ ë¶„ì„
    for complexity, times in complexity_groups.items():
        if times:
            analysis['performance_trends'][complexity] = {
                'avg_time': statistics.mean(times),
                'sample_count': len(times)
            }

    # ê¶Œì¥ì‚¬í•­ ìƒì„±
    recommendations = []

    # ë³µì¡ë„ì— ë”°ë¥¸ ì‹œê°„ ì¦ê°€ ë¶„ì„
    if all(complexity in analysis['performance_trends'] for complexity in ['low', 'medium', 'high']):
        low_time = analysis['performance_trends']['low']['avg_time']
        high_time = analysis['performance_trends']['high']['avg_time']

        if high_time > low_time * 2:
            recommendations.append(f"ë³µì¡í•œ í…œí”Œë¦¿ì€ ê°„ë‹¨í•œ í…œí”Œë¦¿ë³´ë‹¤ {high_time/low_time:.1f}ë°° ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. ë³µì¡ë„ë³„ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    # ì „ì²´ ì‹œê°„ ë¶„ì„
    if analysis['summary'].get('avg_time', 0) > 30:
        recommendations.append("í‰ê·  ì²˜ë¦¬ ì‹œê°„ì´ 30ì´ˆë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. LLM í˜¸ì¶œ ìµœì í™”ê°€ ì‹œê¸‰í•©ë‹ˆë‹¤.")

    # ì¼ê´€ì„± ë¶„ì„
    if analysis['summary'].get('std_dev', 0) > 10:
        recommendations.append("ì²˜ë¦¬ ì‹œê°„ì˜ í¸ì°¨ê°€ í½ë‹ˆë‹¤. ì•ˆì •ì„± ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    analysis['recommendations'] = recommendations

    return analysis

def generate_detailed_report(results: Dict, analysis: Dict) -> str:
    """ìƒì„¸ ë³´ê³ ì„œ ìƒì„±"""
    report_lines = []

    report_lines.append("=" * 80)
    report_lines.append("ì¹´ì¹´ì˜¤í†¡ í…œí”Œë¦¿ ìƒì„± ìƒì„¸ ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œ")
    report_lines.append("=" * 80)
    report_lines.append(f"í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append("")

    # ì „ì²´ ìš”ì•½
    if 'summary' in analysis and analysis['summary']:
        summary = analysis['summary']
        report_lines.append("ğŸ“Š ì „ì²´ ì„±ëŠ¥ ìš”ì•½")
        report_lines.append("-" * 50)
        report_lines.append(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {summary['total_tests']}")
        report_lines.append(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {summary['avg_time']:.2f}ì´ˆ")
        report_lines.append(f"ì¤‘ê°„ê°’ ì²˜ë¦¬ ì‹œê°„: {summary['median_time']:.2f}ì´ˆ")
        report_lines.append(f"ìµœì†Œ ì²˜ë¦¬ ì‹œê°„: {summary['min_time']:.2f}ì´ˆ")
        report_lines.append(f"ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„: {summary['max_time']:.2f}ì´ˆ")
        report_lines.append(f"í‘œì¤€í¸ì°¨: {summary['std_dev']:.2f}ì´ˆ")
        report_lines.append("")

    # ë³µì¡ë„ë³„ ë¶„ì„
    report_lines.append("ğŸ¯ ë³µì¡ë„ë³„ ì„±ëŠ¥ ë¶„ì„")
    report_lines.append("-" * 50)

    for test_name, data in analysis['by_complexity'].items():
        report_lines.append(f"â€¢ {test_name} ({data['complexity']} ë³µì¡ë„)")
        report_lines.append(f"  í‰ê·  ì‹œê°„: {data['avg_time']:.2f}ì´ˆ")
        report_lines.append(f"  í‰ê·  í…œí”Œë¦¿ ê¸¸ì´: {data['avg_template_length']:.0f}ì")
        report_lines.append(f"  í‰ê·  ì»´í”Œë¼ì´ì–¸ìŠ¤ ì ìˆ˜: {data['avg_compliance_score']:.1f}ì ")
        report_lines.append(f"  ì„±ê³µë¥ : {data['success_rate']:.1f}%")
        report_lines.append("")

    # ë³µì¡ë„ íŠ¸ë Œë“œ
    if analysis['performance_trends']:
        report_lines.append("ğŸ“ˆ ë³µì¡ë„ë³„ ì²˜ë¦¬ ì‹œê°„ íŠ¸ë Œë“œ")
        report_lines.append("-" * 50)

        for complexity, trend_data in analysis['performance_trends'].items():
            report_lines.append(f"{complexity.upper()} ë³µì¡ë„: {trend_data['avg_time']:.2f}ì´ˆ (ìƒ˜í”Œ {trend_data['sample_count']}ê°œ)")
        report_lines.append("")

    # ê¶Œì¥ì‚¬í•­
    if analysis['recommendations']:
        report_lines.append("ğŸ’¡ ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­")
        report_lines.append("-" * 50)
        for i, rec in enumerate(analysis['recommendations'], 1):
            report_lines.append(f"{i}. {rec}")
        report_lines.append("")

    # ì„¸ë¶€ í…ŒìŠ¤íŠ¸ ê²°ê³¼
    report_lines.append("ğŸ“‹ ì„¸ë¶€ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    report_lines.append("-" * 50)

    for test_name, test_data in results.items():
        report_lines.append(f"\n{test_name} ({test_data['complexity']} ë³µì¡ë„):")

        for result in test_data['results']:
            if result.get('success', False):
                report_lines.append(f"  ë°˜ë³µ {result['iteration']}: {result['total_time']:.2f}ì´ˆ "
                                  f"(ê¸¸ì´: {result['template_length']}ì, ì ìˆ˜: {result['compliance_score']})")
            else:
                report_lines.append(f"  ë°˜ë³µ {result['iteration']}: ì‹¤íŒ¨ - {result.get('error', 'Unknown error')}")

    return "\n".join(report_lines)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ìƒì„¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    # ì„œë²„ ì—°ê²° í™•ì¸
    try:
        response = requests.get("http://localhost:8000/health", timeout=10)
        if response.status_code != 200:
            print("âŒ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
    except Exception as e:
        print(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        return

    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = run_detailed_performance_test()

    # ê²°ê³¼ ë¶„ì„
    analysis = analyze_detailed_results(results)

    # ë³´ê³ ì„œ ìƒì„±
    report = generate_detailed_report(results, analysis)

    print("\n" + "="*80)
    print("ìƒì„¸ ì„±ëŠ¥ ë¶„ì„ ì™„ë£Œ!")
    print("="*80)
    print(report)

    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    filename = f"detailed_performance_results_{timestamp}.json"

    output_data = {
        'test_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
        'test_cases': DETAILED_TEST_CASES,
        'results': results,
        'analysis': analysis
    }

    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“„ ìƒì„¸ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()