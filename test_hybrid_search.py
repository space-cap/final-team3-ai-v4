#!/usr/bin/env python3
"""
í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ ê²€ì¦ ë° ë¶„ì„
"""

import os
import sys
import json
import time
from datetime import datetime
from typing import List, Dict, Any
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append('src')

try:
    from search.hybrid_search import HybridSearchEngine
    from search.korean_tokenizer import KoreanTokenizer
    from search.bm25_policy_search import BM25PolicySearch
except ImportError as e:
    print(f"ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    print("src/search ë””ë ‰í† ë¦¬ì™€ ëª¨ë“ˆë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


class HybridSearchTester:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.results = {
            'test_start_time': datetime.now().isoformat(),
            'environment': {
                'python_version': sys.version,
                'hybrid_search_enabled': os.getenv('HYBRID_SEARCH_ENABLED', 'false'),
                'vector_weight': float(os.getenv('VECTOR_SEARCH_WEIGHT', '0.7')),
                'bm25_weight': float(os.getenv('BM25_SEARCH_WEIGHT', '0.3')),
                'use_konlpy': os.getenv('USE_KONLPY', 'true').lower() == 'true'
            },
            'tests': [],
            'performance_summary': {}
        }

    def test_tokenizer(self) -> Dict[str, Any]:
        """í•œêµ­ì–´ í† í°í™” í…ŒìŠ¤íŠ¸"""
        print("\n=== 1. í•œêµ­ì–´ í† í°í™” í…ŒìŠ¤íŠ¸ ===")

        tokenizer = KoreanTokenizer(use_konlpy=self.results['environment']['use_konlpy'])

        test_texts = [
            "ì•ˆë…•í•˜ì„¸ìš” #{ê³ ê°ëª…}ë‹˜, ì£¼ë¬¸í•˜ì‹  ìƒí’ˆì´ ë°°ì†¡ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "ì¹´ì¹´ì˜¤í†¡ ì•Œë¦¼í†¡ í…œí”Œë¦¿ ì •ì±…ì„ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.",
            "ì˜ì—…ì‹œê°„ì€ í‰ì¼ 09:00~18:00ì…ë‹ˆë‹¤. ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì—°ë½ì£¼ì„¸ìš”.",
            "ì´ë²¤íŠ¸ ì°¸ì—¬ ê°ì‚¬í•©ë‹ˆë‹¤! ë‹¹ì²¨ì ë°œí‘œëŠ” #{ë°œí‘œì¼}ì— ì§„í–‰ë©ë‹ˆë‹¤."
        ]

        tokenization_results = []

        for i, text in enumerate(test_texts, 1):
            start_time = time.time()
            tokens = tokenizer.tokenize(text)
            tokenization_time = time.time() - start_time

            result = {
                'text_id': i,
                'original_text': text,
                'tokens': tokens,
                'token_count': len(tokens),
                'tokenization_time': tokenization_time,
                'avg_time_per_char': tokenization_time / len(text) if text else 0
            }

            tokenization_results.append(result)

            print(f"{i}. ì›ë³¸: {text}")
            print(f"   í† í°: {tokens}")
            print(f"   ì‹œê°„: {tokenization_time:.4f}ì´ˆ ({len(tokens)}ê°œ í† í°)")

        return {
            'test_name': 'korean_tokenization',
            'results': tokenization_results,
            'summary': {
                'total_texts': len(test_texts),
                'avg_tokens_per_text': sum(r['token_count'] for r in tokenization_results) / len(tokenization_results),
                'avg_tokenization_time': sum(r['tokenization_time'] for r in tokenization_results) / len(tokenization_results)
            }
        }

    def test_bm25_search(self) -> Dict[str, Any]:
        """BM25 ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        print("\n=== 2. BM25 ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")

        try:
            bm25_search = BM25PolicySearch(use_konlpy=self.results['environment']['use_konlpy'])

            # ë°ì´í„° ë¡œë“œ
            template_file = os.getenv('TEMPLATE_DATA_PATH', 'data/kakao_template_vectordb_data.json')
            policy_dir = os.getenv('POLICY_DATA_PATH', 'data/cleaned_policies')

            load_start = time.time()

            template_count = 0
            policy_count = 0

            if os.path.exists(template_file):
                template_count = bm25_search.load_template_data(template_file)
                print(f"í…œí”Œë¦¿ ë¡œë“œ: {template_count}ê°œ")

            if os.path.exists(policy_dir):
                policy_count = bm25_search.load_policy_documents(policy_dir)
                print(f"ì •ì±… ë¬¸ì„œ ë¡œë“œ: {policy_count}ê°œ")

            # ì¸ë±ìŠ¤ êµ¬ì¶•
            index_success = bm25_search.build_index()
            load_time = time.time() - load_start

            if not index_success:
                return {
                    'test_name': 'bm25_search',
                    'error': 'BM25 ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨',
                    'load_time': load_time
                }

            # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
            test_queries = [
                "ë°°ì†¡ ì•Œë¦¼ í…œí”Œë¦¿",
                "ì£¼ë¬¸ í™•ì¸ ë©”ì‹œì§€",
                "ì •ì±… ì¤€ìˆ˜ ê°€ì´ë“œë¼ì¸",
                "ê¸ˆì§€ëœ ë‚´ìš©",
                "íšŒì› ê°€ì… ì¶•í•˜",
                "ì´ë²¤íŠ¸ ë‹¹ì²¨ ì•ˆë‚´"
            ]

            query_results = []

            for query in test_queries:
                search_start = time.time()
                results = bm25_search.search(query, top_k=5)
                search_time = time.time() - search_start

                query_result = {
                    'query': query,
                    'result_count': len(results),
                    'search_time': search_time,
                    'top_scores': [r['bm25_score'] for r in results[:3]],
                    'avg_score': sum(r['bm25_score'] for r in results) / len(results) if results else 0
                }

                query_results.append(query_result)

                print(f"ì¿¼ë¦¬: '{query}' -> {len(results)}ê°œ ê²°ê³¼ ({search_time:.4f}ì´ˆ)")
                for i, result in enumerate(results[:2], 1):
                    print(f"  {i}. {result['type']}: {result['id']} (ì ìˆ˜: {result['bm25_score']:.3f})")

            return {
                'test_name': 'bm25_search',
                'data_loading': {
                    'template_count': template_count,
                    'policy_count': policy_count,
                    'load_time': load_time,
                    'index_success': index_success
                },
                'query_results': query_results,
                'summary': {
                    'total_queries': len(test_queries),
                    'avg_search_time': sum(r['search_time'] for r in query_results) / len(query_results),
                    'avg_results_per_query': sum(r['result_count'] for r in query_results) / len(query_results)
                }
            }

        except Exception as e:
            return {
                'test_name': 'bm25_search',
                'error': f'BM25 ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}'
            }

    def test_hybrid_search(self) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        print("\n=== 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")

        try:
            # í™˜ê²½ ì„¤ì •ì—ì„œ ê°€ì¤‘ì¹˜ ë¡œë“œ
            vector_weight = self.results['environment']['vector_weight']
            bm25_weight = self.results['environment']['bm25_weight']

            hybrid_engine = HybridSearchEngine(
                vector_weight=vector_weight,
                bm25_weight=bm25_weight,
                use_konlpy=self.results['environment']['use_konlpy']
            )

            # ë°ì´í„° ì´ˆê¸°í™”
            init_start = time.time()
            init_success = hybrid_engine.initialize_data()
            init_time = time.time() - init_start

            if not init_success:
                return {
                    'test_name': 'hybrid_search',
                    'error': 'í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°ì´í„° ì´ˆê¸°í™” ì‹¤íŒ¨',
                    'init_time': init_time
                }

            print(f"ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ ({init_time:.2f}ì´ˆ)")

            # ê²€ìƒ‰ ë°©ë²•ë³„ ë¹„êµ í…ŒìŠ¤íŠ¸
            test_queries = [
                "ë°°ì†¡ ì•Œë¦¼ í…œí”Œë¦¿",
                "ì£¼ë¬¸ í™•ì¸ ë©”ì‹œì§€",
                "ì •ì±… ì¤€ìˆ˜ ê°€ì´ë“œë¼ì¸"
            ]

            comparison_results = []

            for query in test_queries:
                print(f"\në¹„êµ í…ŒìŠ¤íŠ¸: '{query}'")

                comparison = hybrid_engine.compare_search_methods(query, top_k=5)
                comparison_results.append(comparison)

                # ê²°ê³¼ ì¶œë ¥
                for method, data in comparison['methods'].items():
                    print(f"  [{method.upper()}] {data['result_count']}ê°œ ê²°ê³¼, {data['search_time']:.4f}ì´ˆ, í‰ê· ì ìˆ˜: {data['avg_score']:.3f}")

            # ì„±ëŠ¥ í†µê³„
            stats = hybrid_engine.get_search_stats()

            return {
                'test_name': 'hybrid_search',
                'initialization': {
                    'success': init_success,
                    'init_time': init_time
                },
                'comparison_results': comparison_results,
                'performance_stats': stats,
                'configuration': {
                    'vector_weight': vector_weight,
                    'bm25_weight': bm25_weight
                }
            }

        except Exception as e:
            return {
                'test_name': 'hybrid_search',
                'error': f'í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}'
            }

    def run_performance_benchmark(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
        print("\n=== 4. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ===")

        try:
            # ëŒ€ëŸ‰ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
            benchmark_queries = [
                "ë°°ì†¡", "ì£¼ë¬¸", "ê²°ì œ", "íšŒì›", "ì´ë²¤íŠ¸", "ì¿ í°", "ì ë¦½", "í˜œíƒ",
                "ì•ˆë‚´", "ì•Œë¦¼", "ê³µì§€", "ë³€ê²½", "ì·¨ì†Œ", "í™˜ë¶ˆ", "êµí™˜", "ë¬¸ì˜",
                "ì„œë¹„ìŠ¤", "ìƒí’ˆ", "í• ì¸", "íŠ¹ê°€", "ì‹ ê·œ", "ê¸°ì¡´", "VIP", "ë“±ê¸‰"
            ]

            vector_weight = self.results['environment']['vector_weight']
            bm25_weight = self.results['environment']['bm25_weight']

            hybrid_engine = HybridSearchEngine(
                vector_weight=vector_weight,
                bm25_weight=bm25_weight
            )

            if not hybrid_engine.initialize_data():
                return {
                    'test_name': 'performance_benchmark',
                    'error': 'ë°ì´í„° ì´ˆê¸°í™” ì‹¤íŒ¨'
                }

            # ê° ê²€ìƒ‰ ë°©ë²•ë³„ ì„±ëŠ¥ ì¸¡ì •
            methods = ['vector', 'bm25', 'hybrid']
            benchmark_results = {}

            for method in methods:
                print(f"\n{method.upper()} ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")

                method_start = time.time()
                total_results = 0
                search_times = []

                for query in benchmark_queries:
                    search_start = time.time()
                    results = hybrid_engine.search(query, top_k=10, search_type=method)
                    search_time = time.time() - search_start

                    total_results += len(results)
                    search_times.append(search_time)

                method_total_time = time.time() - method_start

                benchmark_results[method] = {
                    'total_queries': len(benchmark_queries),
                    'total_results': total_results,
                    'total_time': method_total_time,
                    'avg_time_per_query': method_total_time / len(benchmark_queries),
                    'min_search_time': min(search_times),
                    'max_search_time': max(search_times),
                    'avg_search_time': sum(search_times) / len(search_times),
                    'avg_results_per_query': total_results / len(benchmark_queries)
                }

                print(f"  ì´ ì‹œê°„: {method_total_time:.3f}ì´ˆ")
                print(f"  í‰ê·  ì¿¼ë¦¬ë‹¹: {benchmark_results[method]['avg_time_per_query']:.4f}ì´ˆ")
                print(f"  í‰ê·  ê²°ê³¼ìˆ˜: {benchmark_results[method]['avg_results_per_query']:.1f}ê°œ")

            return {
                'test_name': 'performance_benchmark',
                'benchmark_results': benchmark_results,
                'query_count': len(benchmark_queries)
            }

        except Exception as e:
            return {
                'test_name': 'performance_benchmark',
                'error': f'ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}'
            }

    def run_all_tests(self) -> None:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"í™˜ê²½ ì„¤ì •: Vector({self.results['environment']['vector_weight']}) + BM25({self.results['environment']['bm25_weight']})")

        # ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        tests = [
            self.test_tokenizer,
            self.test_bm25_search,
            self.test_hybrid_search,
            self.run_performance_benchmark
        ]

        for test_func in tests:
            try:
                test_result = test_func()
                self.results['tests'].append(test_result)
            except Exception as e:
                error_result = {
                    'test_name': test_func.__name__,
                    'error': f'í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}'
                }
                self.results['tests'].append(error_result)
                print(f"âŒ {test_func.__name__} ì‹¤íŒ¨: {e}")

        # ì¢…í•© ì„±ëŠ¥ ìš”ì•½
        self._create_performance_summary()

        # ê²°ê³¼ ì €ì¥
        self._save_results()

    def _create_performance_summary(self) -> None:
        """ì„±ëŠ¥ ìš”ì•½ ìƒì„±"""
        summary = {
            'test_completion_time': datetime.now().isoformat(),
            'total_tests': len(self.results['tests']),
            'successful_tests': len([t for t in self.results['tests'] if 'error' not in t]),
            'failed_tests': len([t for t in self.results['tests'] if 'error' in t])
        }

        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ ìš”ì•½
        hybrid_test = next((t for t in self.results['tests'] if t.get('test_name') == 'hybrid_search'), None)
        if hybrid_test and 'error' not in hybrid_test:
            perf_stats = hybrid_test.get('performance_stats', {})
            if perf_stats:
                summary['hybrid_performance'] = {
                    'total_searches': perf_stats.get('total_searches', 0),
                    'avg_vector_time': perf_stats.get('avg_vector_time', 0),
                    'avg_bm25_time': perf_stats.get('avg_bm25_time', 0),
                    'avg_fusion_time': perf_stats.get('avg_fusion_time', 0)
                }

        # ë²¤ì¹˜ë§ˆí¬ ì„±ëŠ¥ ìš”ì•½
        benchmark_test = next((t for t in self.results['tests'] if t.get('test_name') == 'performance_benchmark'), None)
        if benchmark_test and 'error' not in benchmark_test:
            benchmark_results = benchmark_test.get('benchmark_results', {})
            summary['benchmark_comparison'] = {}

            for method, data in benchmark_results.items():
                summary['benchmark_comparison'][method] = {
                    'avg_time_per_query': data.get('avg_time_per_query', 0),
                    'avg_results_per_query': data.get('avg_results_per_query', 0)
                }

        self.results['performance_summary'] = summary

    def _save_results(self) -> None:
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"hybrid_search_test_results_{timestamp}.json"

        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2)

            print(f"\nâœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {filename}")

            # ê°„ë‹¨í•œ ìš”ì•½ ì¶œë ¥
            summary = self.results['performance_summary']
            print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ìš”ì•½:")
            print(f"  - ì´ í…ŒìŠ¤íŠ¸: {summary['total_tests']}ê°œ")
            print(f"  - ì„±ê³µ: {summary['successful_tests']}ê°œ")
            print(f"  - ì‹¤íŒ¨: {summary['failed_tests']}ê°œ")

            if 'hybrid_performance' in summary:
                hp = summary['hybrid_performance']
                print(f"  - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰: {hp['total_searches']}íšŒ")
                print(f"  - í‰ê·  ìœµí•© ì‹œê°„: {hp['avg_fusion_time']:.4f}ì´ˆ")

        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # í•„ìˆ˜ ë°ì´í„° íŒŒì¼ í™•ì¸
    template_file = os.getenv('TEMPLATE_DATA_PATH', 'data/kakao_template_vectordb_data.json')
    policy_dir = os.getenv('POLICY_DATA_PATH', 'data/cleaned_policies')

    missing_files = []
    if not os.path.exists(template_file):
        missing_files.append(template_file)
    if not os.path.exists(policy_dir):
        missing_files.append(policy_dir)

    if missing_files:
        print(f"âŒ í•„ìˆ˜ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤:")
        for file_path in missing_files:
            print(f"  - {file_path}")
        print("\në°ì´í„° íŒŒì¼ì„ í™•ì¸í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tester = HybridSearchTester()
    tester.run_all_tests()

    print("\nğŸ‰ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()