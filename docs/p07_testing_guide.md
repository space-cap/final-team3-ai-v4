# P07. í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ (Testing Guide)

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê°œìš”

ì´ ë¬¸ì„œëŠ” ì¹´ì¹´ì˜¤ ì•Œë¦¼í†¡ í…œí”Œë¦¿ ìë™ ìƒì„± AI ì„œë¹„ìŠ¤ì˜ ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ë°©ë²•ê³¼ ì „ëµì„ ì„¤ëª…í•©ë‹ˆë‹¤. ê°œë°œìì™€ ì‚¬ìš©ì ëª¨ë‘ë¥¼ ìœ„í•œ í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“‹ í…ŒìŠ¤íŠ¸ ë ˆë²¨

### 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (Unit Tests)
ê°œë³„ í•¨ìˆ˜ë‚˜ í´ë˜ìŠ¤ì˜ ê¸°ëŠ¥ì„ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸

### 2. í†µí•© í…ŒìŠ¤íŠ¸ (Integration Tests)
ì—¬ëŸ¬ ì»´í¬ë„ŒíŠ¸ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ í…ŒìŠ¤íŠ¸

### 3. ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (System Tests)
ì „ì²´ ì‹œìŠ¤í…œì˜ End-to-End ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸

### 4. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (Performance Tests)
ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ê³¼ í™•ì¥ì„±ì„ í…ŒìŠ¤íŠ¸

### 5. ì‚¬ìš©ì í…ŒìŠ¤íŠ¸ (User Acceptance Tests)
ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í…ŒìŠ¤íŠ¸

## ğŸ›  ê°œë°œì í…ŒìŠ¤íŠ¸

### í™˜ê²½ ì„¤ì •

#### í…ŒìŠ¤íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜
```bash
# ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ë„êµ¬
pip install pytest pytest-cov pytest-mock pytest-asyncio

# ì¶”ê°€ í…ŒìŠ¤íŠ¸ ë„êµ¬
pip install factory-boy faker httpx

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
pip install pytest-benchmark locust
```

#### í…ŒìŠ¤íŠ¸ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env.test íŒŒì¼ ìƒì„±
cp .env.example .env.test

# í…ŒìŠ¤íŠ¸ìš© ì„¤ì • ìˆ˜ì •
ENVIRONMENT=testing
ANTHROPIC_API_KEY=test-key-for-mock
DATABASE_URL=sqlite:///test.db
LOG_LEVEL=DEBUG
```

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

#### 1. ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸

**Request Analyzer í…ŒìŠ¤íŠ¸**:
```python
# tests/unit/test_request_analyzer.py
import pytest
from src.agents.request_analyzer import RequestAnalyzer

class TestRequestAnalyzer:
    """ìš”ì²­ ë¶„ì„ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def analyzer(self):
        return RequestAnalyzer()

    @pytest.mark.parametrize("request,expected_business", [
        ("í”¼ì ì£¼ë¬¸ ì™„ë£Œ ì•ˆë‚´", "ìŒì‹ì "),
        ("ì˜¨ë¼ì¸ ê°•ì˜ ìˆ˜ê°• ì‹ ì²­", "êµìœ¡"),
        ("ì¹˜ê³¼ ì§„ë£Œ ì˜ˆì•½ í™•ì •", "ì˜ë£Œ"),
        ("ì‡¼í•‘ëª° ìƒí’ˆ ë°°ì†¡ ì•ˆë‚´", "ì‡¼í•‘ëª°")
    ])
    def test_business_type_classification(self, analyzer, request, expected_business):
        """ì—…ì¢… ë¶„ë¥˜ ì •í™•ì„± í…ŒìŠ¤íŠ¸"""
        result = analyzer._classify_by_keywords({}, request)
        assert result["business_type"] == expected_business

    def test_confidence_score_calculation(self, analyzer):
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        request = "ì˜¨ë¼ì¸ íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë° ê°•ì˜ ìˆ˜ê°• ì‹ ì²­ ì™„ë£Œ"
        result = analyzer.analyze_request(request)

        assert result["confidence_score"] >= 0.8
        assert result["business_type"] == "êµìœ¡"
        assert "ê°•ì˜ëª…" in result["required_variables"]

    def test_edge_cases(self, analyzer):
        """ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
        edge_cases = [
            "",  # ë¹ˆ ë¬¸ìì—´
            "a" * 2000,  # ë§¤ìš° ê¸´ ë¬¸ìì—´
            "íŠ¹ìˆ˜ë¬¸ì!@#$%^&*()",  # íŠ¹ìˆ˜ë¬¸ì
            "123456789",  # ìˆ«ìë§Œ
        ]

        for case in edge_cases:
            result = analyzer.analyze_request(case)
            # ê¸°ë³¸ê°’ì´ ì„¤ì •ë˜ì–´ì•¼ í•¨
            assert "business_type" in result
            assert "service_type" in result
```

**Template Generator í…ŒìŠ¤íŠ¸**:
```python
# tests/unit/test_template_generator.py
import pytest
from unittest.mock import Mock, patch
from src.agents.template_generator import TemplateGenerator

class TestTemplateGenerator:
    """í…œí”Œë¦¿ ìƒì„± ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_llm_client(self):
        mock_client = Mock()
        mock_client.generate_template.return_value = {
            "template_text": "ì•ˆë…•í•˜ì„¸ìš” #{ìˆ˜ì‹ ìëª…}ë‹˜...",
            "variables": ["ìˆ˜ì‹ ìëª…", "ìƒí’ˆëª…"]
        }
        return mock_client

    @pytest.fixture
    def mock_template_store(self):
        mock_store = Mock()
        mock_store.find_similar_templates.return_value = [
            {
                "text": "ì°¸ê³  í…œí”Œë¦¿",
                "metadata": {"business_type": "êµìœ¡"}
            }
        ]
        return mock_store

    def test_template_generation_success(self, mock_llm_client, mock_template_store):
        """í…œí”Œë¦¿ ìƒì„± ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        generator = TemplateGenerator(mock_llm_client, mock_template_store)

        analysis = {
            "business_type": "êµìœ¡",
            "service_type": "ì‹ ì²­",
            "required_variables": ["ìˆ˜ì‹ ìëª…", "ê°•ì˜ëª…"]
        }

        result = generator.generate_template(analysis, "ì •ì±… ì»¨í…ìŠ¤íŠ¸")

        assert result["success"] is True
        assert "template_text" in result
        assert len(result["variables"]) > 0

    def test_template_optimization(self, mock_llm_client, mock_template_store):
        """í…œí”Œë¦¿ ìµœì í™” í…ŒìŠ¤íŠ¸"""
        generator = TemplateGenerator(mock_llm_client, mock_template_store)

        original_template = "ì•ˆë…•í•˜ì„¸ìš”. ì£¼ë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        feedback = {"missing_variables": ["ìˆ˜ì‹ ìëª…"]}

        optimized = generator._optimize_template(original_template, feedback)

        assert "#{ìˆ˜ì‹ ìëª…}" in optimized
        assert "ì•ˆë…•í•˜ì„¸ìš”" in optimized

    @patch('src.agents.template_generator.time.time')
    def test_generation_timeout(self, mock_time, mock_llm_client, mock_template_store):
        """ìƒì„± íƒ€ì„ì•„ì›ƒ í…ŒìŠ¤íŠ¸"""
        # íƒ€ì„ì•„ì›ƒ ì‹œë®¬ë ˆì´ì…˜
        mock_time.side_effect = [0, 10, 20, 35]  # 35ì´ˆ ê²½ê³¼

        generator = TemplateGenerator(mock_llm_client, mock_template_store)

        with pytest.raises(TimeoutError):
            generator.generate_template({}, "", timeout=30)
```

#### 2. ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸

**LLM Client í…ŒìŠ¤íŠ¸**:
```python
# tests/unit/test_llm_client.py
import pytest
from unittest.mock import Mock, patch
from src.utils.llm_client import ClaudeLLMClient

class TestClaudeLLMClient:
    """Claude LLM í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_anthropic(self):
        with patch('src.utils.llm_client.ChatAnthropic') as mock:
            mock_instance = Mock()
            mock.return_value = mock_instance
            mock_instance.invoke.return_value.content = "í…ŒìŠ¤íŠ¸ ì‘ë‹µ"
            yield mock_instance

    def test_client_initialization(self):
        """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        client = ClaudeLLMClient(api_key="test-key")
        assert client.api_key == "test-key"
        assert client.model == "claude-3-5-haiku-latest"

    def test_api_key_validation(self):
        """API í‚¤ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        with pytest.raises(ValueError, match="API key must be provided"):
            ClaudeLLMClient(api_key=None)

    def test_generate_response(self, mock_anthropic):
        """ì‘ë‹µ ìƒì„± í…ŒìŠ¤íŠ¸"""
        client = ClaudeLLMClient(api_key="test-key")

        response = client.generate_response(
            "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
            "ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸"
        )

        assert response == "í…ŒìŠ¤íŠ¸ ì‘ë‹µ"
        mock_anthropic.invoke.assert_called_once()

    def test_retry_mechanism(self, mock_anthropic):
        """ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸"""
        # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í˜¸ì¶œì€ ì‹¤íŒ¨, ì„¸ ë²ˆì§¸ëŠ” ì„±ê³µ
        mock_anthropic.invoke.side_effect = [
            Exception("API Error"),
            Exception("Network Error"),
            Mock(content="ì„±ê³µ ì‘ë‹µ")
        ]

        client = ClaudeLLMClient(api_key="test-key")
        response = client.generate_response("system", "user")

        assert response == "ì„±ê³µ ì‘ë‹µ"
        assert mock_anthropic.invoke.call_count == 3
```

### í†µí•© í…ŒìŠ¤íŠ¸

#### 1. API í†µí•© í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_api_integration.py
import pytest
from fastapi.testclient import TestClient
from src.api.main import app

class TestAPIIntegration:
    """API í†µí•© í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def client(self):
        return TestClient(app)

    def test_health_endpoint(self, client):
        """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        response = client.get("/health")

        assert response.status_code == 200
        data = response.json()
        assert data["status"] == "healthy"

    def test_template_generation_flow(self, client):
        """í…œí”Œë¦¿ ìƒì„± í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        request_data = {
            "user_request": "í”¼ì ì£¼ë¬¸ ì™„ë£Œ ì•ˆë‚´ ë©”ì‹œì§€",
            "business_type": "ìŒì‹ì ",
            "tone": "ì¹œê·¼í•œ"
        }

        response = client.post("/api/v1/templates/generate", json=request_data)

        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
        assert "template" in data
        assert "compliance" in data

    def test_error_handling(self, client):
        """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # ì˜ëª»ëœ ìš”ì²­ ë°ì´í„°
        invalid_data = {"user_request": ""}

        response = client.post("/api/v1/templates/generate", json=invalid_data)

        assert response.status_code == 400
        data = response.json()
        assert data["success"] is False
        assert "error" in data

    @pytest.mark.asyncio
    async def test_concurrent_requests(self, client):
        """ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        import asyncio
        import httpx

        async def make_request():
            async with httpx.AsyncClient(app=app, base_url="http://test") as ac:
                response = await ac.post(
                    "/api/v1/templates/generate",
                    json={"user_request": "í…ŒìŠ¤íŠ¸ ìš”ì²­"}
                )
                return response.status_code

        # 10ê°œì˜ ë™ì‹œ ìš”ì²­
        tasks = [make_request() for _ in range(10)]
        results = await asyncio.gather(*tasks)

        # ëª¨ë“  ìš”ì²­ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨
        assert all(status == 200 for status in results)
```

#### 2. ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_database_integration.py
import pytest
import tempfile
import shutil
from src.database.vector_store import PolicyVectorStore, TemplateStore

class TestDatabaseIntegration:
    """ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def temp_db_dir(self):
        """ì„ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬"""
        temp_dir = tempfile.mkdtemp()
        yield temp_dir
        shutil.rmtree(temp_dir)

    @pytest.fixture
    def vector_store(self, temp_db_dir):
        """ë²¡í„° ìŠ¤í† ì–´ ì¸ìŠ¤í„´ìŠ¤"""
        return PolicyVectorStore(persist_directory=temp_db_dir)

    def test_policy_document_loading(self, vector_store):
        """ì •ì±… ë¬¸ì„œ ë¡œë”© í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ìš© ì •ì±… ë¬¸ì„œ ìƒì„±
        test_policy_dir = "tests/fixtures/test_policies"

        vector_store.load_policy_documents(test_policy_dir)

        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        results = vector_store.search_relevant_policies("ì•Œë¦¼í†¡ ìŠ¹ì¸", k=3)

        assert len(results) > 0
        assert all("content" in result for result in results)

    def test_template_store_operations(self):
        """í…œí”Œë¦¿ ìŠ¤í† ì–´ ì—°ì‚° í…ŒìŠ¤íŠ¸"""
        template_store = TemplateStore("tests/fixtures/test_templates.json")

        # ì—…ì¢…ë³„ í…œí”Œë¦¿ ê²€ìƒ‰
        education_templates = template_store.get_templates_by_business_type("êµìœ¡")
        assert len(education_templates) > 0

        # ìŠ¹ì¸ëœ í…œí”Œë¦¿ë§Œ í•„í„°ë§
        approved_templates = template_store.get_approved_templates()
        assert all(
            t["metadata"]["approval_status"] == "approved"
            for t in approved_templates
        )

    def test_data_consistency(self, vector_store):
        """ë°ì´í„° ì¼ê´€ì„± í…ŒìŠ¤íŠ¸"""
        # ë™ì¼í•œ ê²€ìƒ‰ì–´ë¡œ ì—¬ëŸ¬ ë²ˆ ê²€ìƒ‰
        query = "ì•Œë¦¼í†¡ í…œí”Œë¦¿"

        results1 = vector_store.search_relevant_policies(query, k=5)
        results2 = vector_store.search_relevant_policies(query, k=5)

        # ê²°ê³¼ê°€ ì¼ê´€ë˜ì–´ì•¼ í•¨
        assert len(results1) == len(results2)
        assert results1[0]["content"] == results2[0]["content"]
```

### ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

#### End-to-End í…ŒìŠ¤íŠ¸

```python
# tests/e2e/test_complete_workflow.py
import pytest
from src.workflow.langgraph_workflow import TemplateGenerationWorkflow

class TestCompleteWorkflow:
    """ì™„ì „í•œ ì›Œí¬í”Œë¡œìš° E2E í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def workflow(self):
        return TemplateGenerationWorkflow()

    @pytest.mark.slow
    def test_education_template_workflow(self, workflow):
        """êµìœ¡ì—… í…œí”Œë¦¿ ìƒì„± ì›Œí¬í”Œë¡œìš°"""
        input_data = {
            "user_request": "ì˜¨ë¼ì¸ íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë° ê°•ì˜ ìˆ˜ê°• ì‹ ì²­ ì™„ë£Œ ì•ˆë‚´",
            "business_type": "êµìœ¡"
        }

        result = workflow.run(input_data)

        # ì›Œí¬í”Œë¡œìš° ì™„ë£Œ í™•ì¸
        assert result["success"] is True
        assert result["final_result"]["compliance"]["score"] >= 80

        # í…œí”Œë¦¿ í’ˆì§ˆ í™•ì¸
        template_text = result["final_result"]["template"]["text"]
        assert "ì•ˆë…•í•˜ì„¸ìš”" in template_text
        assert "#{" in template_text  # ë³€ìˆ˜ í¬í•¨
        assert "ì •ë³´ì„±" in template_text or "ì•ˆë‚´" in template_text

    @pytest.mark.slow
    def test_multiple_iterations_workflow(self, workflow):
        """ë‹¤ì¤‘ ë°˜ë³µ ê°œì„  ì›Œí¬í”Œë¡œìš°"""
        input_data = {
            "user_request": "ëª¨í˜¸í•œ ìš”ì²­",  # ì˜ë„ì ìœ¼ë¡œ ëª¨í˜¸í•œ ìš”ì²­
            "auto_refine": True
        }

        result = workflow.run(input_data)

        # ë°˜ë³µ ê°œì„  í™•ì¸
        assert result["iterations"] > 1
        final_score = result["final_result"]["compliance"]["score"]
        initial_score = result["history"][0]["compliance"]["score"]
        assert final_score > initial_score

    @pytest.mark.parametrize("business_type,expected_keywords", [
        ("êµìœ¡", ["ê°•ì˜", "ìˆ˜ê°•", "í•™ìŠµ"]),
        ("ì˜ë£Œ", ["ì§„ë£Œ", "ì˜ˆì•½", "ë³‘ì›"]),
        ("ìŒì‹ì ", ["ì£¼ë¬¸", "ë©”ë‰´", "í”½ì—…"]),
        ("ì‡¼í•‘ëª°", ["ì£¼ë¬¸", "ë°°ì†¡", "ìƒí’ˆ"])
    ])
    def test_business_specific_templates(self, workflow, business_type, expected_keywords):
        """ì—…ì¢…ë³„ íŠ¹í™” í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸"""
        input_data = {
            "user_request": f"{business_type} ì„œë¹„ìŠ¤ ì™„ë£Œ ì•ˆë‚´",
            "business_type": business_type
        }

        result = workflow.run(input_data)
        template_text = result["final_result"]["template"]["text"]

        # ì—…ì¢… ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ í™•ì¸
        assert any(keyword in template_text for keyword in expected_keywords)
```

### ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

#### 1. ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸

```python
# tests/performance/test_response_time.py
import pytest
import time
from src.api.main import app
from fastapi.testclient import TestClient

class TestPerformance:
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def client(self):
        return TestClient(app)

    def test_template_generation_speed(self, client):
        """í…œí”Œë¦¿ ìƒì„± ì†ë„ í…ŒìŠ¤íŠ¸"""
        request_data = {
            "user_request": "í”¼ì ì£¼ë¬¸ ì™„ë£Œ ì•ˆë‚´",
            "business_type": "ìŒì‹ì "
        }

        start_time = time.time()
        response = client.post("/api/v1/templates/generate", json=request_data)
        end_time = time.time()

        response_time = end_time - start_time

        # 5ì´ˆ ì´ë‚´ ì‘ë‹µ
        assert response_time < 5.0
        assert response.status_code == 200

    @pytest.mark.benchmark
    def test_concurrent_performance(self, client):
        """ë™ì‹œ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        import concurrent.futures

        def make_request():
            return client.post(
                "/api/v1/templates/generate",
                json={"user_request": "í…ŒìŠ¤íŠ¸ ìš”ì²­"}
            )

        # 50ê°œ ë™ì‹œ ìš”ì²­
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            start_time = time.time()
            futures = [executor.submit(make_request) for _ in range(50)]
            responses = [future.result() for future in futures]
            end_time = time.time()

        total_time = end_time - start_time
        successful_requests = sum(1 for r in responses if r.status_code == 200)

        # ì„±ëŠ¥ ê¸°ì¤€
        assert total_time < 60.0  # 1ë¶„ ì´ë‚´
        assert successful_requests >= 45  # 90% ì´ìƒ ì„±ê³µ
```

#### 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸

```python
# tests/performance/test_memory_usage.py
import pytest
import psutil
import os
from src.workflow.langgraph_workflow import TemplateGenerationWorkflow

class TestMemoryUsage:
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""

    def test_memory_consumption(self):
        """ë©”ëª¨ë¦¬ ì†Œë¹„ëŸ‰ í…ŒìŠ¤íŠ¸"""
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        # ëŒ€ëŸ‰ í…œí”Œë¦¿ ìƒì„±
        workflow = TemplateGenerationWorkflow()

        for i in range(100):
            result = workflow.run({
                "user_request": f"í…ŒìŠ¤íŠ¸ ìš”ì²­ {i}",
                "business_type": "êµìœ¡"
            })

        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory

        # ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ì´ 500MB ì´í•˜
        assert memory_increase < 500

    def test_memory_leak_detection(self):
        """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€ í…ŒìŠ¤íŠ¸"""
        import gc

        process = psutil.Process(os.getpid())
        workflow = TemplateGenerationWorkflow()

        memory_readings = []

        for cycle in range(10):
            # 50ê°œ ìš”ì²­ ì²˜ë¦¬
            for i in range(50):
                workflow.run({"user_request": f"í…ŒìŠ¤íŠ¸ {i}"})

            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
            gc.collect()

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë¡
            current_memory = process.memory_info().rss / 1024 / 1024
            memory_readings.append(current_memory)

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ì§€ ì•Šì•„ì•¼ í•¨
        memory_trend = memory_readings[-1] - memory_readings[0]
        assert memory_trend < 50  # 50MB ë¯¸ë§Œ ì¦ê°€
```

## ğŸ‘¥ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸

### ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

#### 1. ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

**ì‹œë‚˜ë¦¬ì˜¤ 1: êµìœ¡ì—… í…œí”Œë¦¿ ìƒì„±**
```
1. ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8000/docs ì ‘ì†
2. POST /api/v1/templates/generate ì—”ë“œí¬ì¸íŠ¸ í´ë¦­
3. "Try it out" ë²„íŠ¼ í´ë¦­
4. ë‹¤ìŒ ë°ì´í„° ì…ë ¥:
   {
     "user_request": "ì˜¨ë¼ì¸ ì˜ì–´ ê°•ì˜ ìˆ˜ê°• ì‹ ì²­ ì™„ë£Œ ì•ˆë‚´",
     "business_type": "êµìœ¡",
     "tone": "ì •ì¤‘í•œ"
   }
5. Execute ë²„íŠ¼ í´ë¦­
6. ì‘ë‹µ í™•ì¸:
   - success: true
   - compliance.score >= 85
   - template.textì— ì¸ì‚¬ë§ í¬í•¨
   - variables ë°°ì—´ì— ì ì ˆí•œ ë³€ìˆ˜ë“¤ í¬í•¨
```

**ì‹œë‚˜ë¦¬ì˜¤ 2: ì˜ë£Œì—… í…œí”Œë¦¿ ìƒì„±**
```
1. ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ì—ì„œ
2. ë‹¤ìŒ ë°ì´í„° ì…ë ¥:
   {
     "user_request": "ì¹˜ê³¼ ì§„ë£Œ ì˜ˆì•½ í™•ì • ë° ë‚´ì› ì‹œ ì¤€ë¹„ì‚¬í•­ ì•ˆë‚´",
     "business_type": "ì˜ë£Œ"
   }
3. ê²°ê³¼ í™•ì¸:
   - ì˜ë£Œì—… íŠ¹í™” ìš©ì–´ ì‚¬ìš©
   - ì˜ˆì•½ ê´€ë ¨ ë³€ìˆ˜ í¬í•¨
   - ì¤€ë¹„ì‚¬í•­ ì•ˆë‚´ ë‚´ìš© í¬í•¨
```

#### 2. ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸

**ì‹œë‚˜ë¦¬ì˜¤ 3: ì˜ëª»ëœ ì…ë ¥ ì²˜ë¦¬**
```
1. ë¹ˆ ìš”ì²­ìœ¼ë¡œ í…ŒìŠ¤íŠ¸:
   {"user_request": ""}
2. ì˜ˆìƒ ê²°ê³¼:
   - 400 Bad Request
   - ì ì ˆí•œ ì˜¤ë¥˜ ë©”ì‹œì§€

3. ë§¤ìš° ê¸´ ìš”ì²­ìœ¼ë¡œ í…ŒìŠ¤íŠ¸:
   {"user_request": "a" * 2000}
4. ì˜ˆìƒ ê²°ê³¼:
   - ì •ìƒ ì²˜ë¦¬ ë˜ëŠ” ì ì ˆí•œ ê¸¸ì´ ì œí•œ ë©”ì‹œì§€
```

### ìë™í™”ëœ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸

#### Seleniumì„ ì´ìš©í•œ ì›¹ UI í…ŒìŠ¤íŠ¸

```python
# tests/user/test_web_interface.py
import pytest
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

class TestWebInterface:
    """ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def driver(self):
        options = webdriver.ChromeOptions()
        options.add_argument("--headless")  # CI í™˜ê²½ìš©
        driver = webdriver.Chrome(options=options)
        yield driver
        driver.quit()

    def test_swagger_ui_accessibility(self, driver):
        """Swagger UI ì ‘ê·¼ì„± í…ŒìŠ¤íŠ¸"""
        driver.get("http://localhost:8000/docs")

        # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        wait = WebDriverWait(driver, 10)

        # Swagger UI ë¡œë”© í™•ì¸
        swagger_ui = wait.until(
            EC.presence_of_element_located((By.CLASS_NAME, "swagger-ui"))
        )
        assert swagger_ui is not None

    def test_api_endpoint_interaction(self, driver):
        """API ì—”ë“œí¬ì¸íŠ¸ ìƒí˜¸ì‘ìš© í…ŒìŠ¤íŠ¸"""
        driver.get("http://localhost:8000/docs")
        wait = WebDriverWait(driver, 10)

        # generate ì—”ë“œí¬ì¸íŠ¸ í´ë¦­
        generate_endpoint = wait.until(
            EC.element_to_be_clickable((By.XPATH, "//span[contains(text(), '/api/v1/templates/generate')]"))
        )
        generate_endpoint.click()

        # Try it out ë²„íŠ¼ í´ë¦­
        try_it_out = wait.until(
            EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), 'Try it out')]"))
        )
        try_it_out.click()

        # ìš”ì²­ ë°ì´í„° ì…ë ¥
        request_body = driver.find_element(By.CLASS_NAME, "body-param__text")
        test_data = '{"user_request": "í”¼ì ì£¼ë¬¸ ì™„ë£Œ ì•ˆë‚´"}'
        request_body.clear()
        request_body.send_keys(test_data)

        # Execute ë²„íŠ¼ í´ë¦­
        execute_button = driver.find_element(By.XPATH, "//button[contains(text(), 'Execute')]")
        execute_button.click()

        # ì‘ë‹µ í™•ì¸
        response_body = wait.until(
            EC.presence_of_element_located((By.CLASS_NAME, "response-col_description"))
        )
        assert "success" in response_body.text
```

### ë¶€í•˜ í…ŒìŠ¤íŠ¸

#### Locustë¥¼ ì´ìš©í•œ ë¶€í•˜ í…ŒìŠ¤íŠ¸

```python
# tests/load/locustfile.py
from locust import HttpUser, task, between
import json

class TemplateGenerationUser(HttpUser):
    """í…œí”Œë¦¿ ìƒì„± ì‚¬ìš©ì ì‹œë®¬ë ˆì´ì…˜"""

    wait_time = between(1, 3)  # 1-3ì´ˆ ëŒ€ê¸°

    def on_start(self):
        """í…ŒìŠ¤íŠ¸ ì‹œì‘ ì‹œ ì‹¤í–‰"""
        self.test_requests = [
            "í”¼ì ì£¼ë¬¸ ì™„ë£Œ ì•ˆë‚´",
            "ì˜¨ë¼ì¸ ê°•ì˜ ìˆ˜ê°• ì‹ ì²­ ì™„ë£Œ",
            "ì¹˜ê³¼ ì§„ë£Œ ì˜ˆì•½ í™•ì •",
            "ì‡¼í•‘ëª° ìƒí’ˆ ë°°ì†¡ ì‹œì‘",
            "í—¬ìŠ¤ì¥ íšŒì›ê¶Œ ë“±ë¡ ì™„ë£Œ"
        ]

    @task(3)
    def generate_template(self):
        """í…œí”Œë¦¿ ìƒì„± ì‘ì—… (ê°€ì¤‘ì¹˜ 3)"""
        import random

        request_data = {
            "user_request": random.choice(self.test_requests),
            "tone": random.choice(["ì •ì¤‘í•œ", "ì¹œê·¼í•œ", "ê³µì‹ì ì¸"])
        }

        with self.client.post(
            "/api/v1/templates/generate",
            json=request_data,
            catch_response=True
        ) as response:
            if response.status_code == 200:
                response_data = response.json()
                if response_data.get("success"):
                    response.success()
                else:
                    response.failure("API returned success=false")
            else:
                response.failure(f"HTTP {response.status_code}")

    @task(1)
    def health_check(self):
        """í—¬ìŠ¤ì²´í¬ ì‘ì—… (ê°€ì¤‘ì¹˜ 1)"""
        with self.client.get("/health", catch_response=True) as response:
            if response.status_code == 200:
                response.success()
            else:
                response.failure(f"Health check failed: {response.status_code}")

    @task(1)
    def validate_template(self):
        """í…œí”Œë¦¿ ê²€ì¦ ì‘ì—… (ê°€ì¤‘ì¹˜ 1)"""
        template_data = {
            "template_text": "ì•ˆë…•í•˜ì„¸ìš” #{ìˆ˜ì‹ ìëª…}ë‹˜, ì£¼ë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "variables": ["ìˆ˜ì‹ ìëª…"],
            "business_type": "ìŒì‹ì "
        }

        with self.client.post(
            "/api/v1/templates/validate",
            json=template_data,
            catch_response=True
        ) as response:
            if response.status_code == 200:
                response.success()
            else:
                response.failure(f"Validation failed: {response.status_code}")
```

**ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰**:
```bash
# 10ëª… ì‚¬ìš©ì, ì´ˆë‹¹ 2ëª…ì”© ì¦ê°€, 60ì´ˆê°„ í…ŒìŠ¤íŠ¸
locust -f tests/load/locustfile.py --host=http://localhost:8000 -u 10 -r 2 -t 60s --headless

# ì›¹ UIë¡œ ì‹¤í–‰
locust -f tests/load/locustfile.py --host=http://localhost:8000
```

## ğŸ“Š í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ë¦¬í¬íŒ…

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëª…ë ¹ì–´

#### ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest

# íŠ¹ì • ë””ë ‰í† ë¦¬ë§Œ
pytest tests/unit/

# íŠ¹ì • íŒŒì¼ë§Œ
pytest tests/unit/test_request_analyzer.py

# íŠ¹ì • í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë§Œ
pytest tests/unit/test_request_analyzer.py::TestRequestAnalyzer::test_business_type_classification

# ë§ˆì»¤ ê¸°ë°˜ ì‹¤í–‰
pytest -m "not slow"  # slow ë§ˆì»¤ê°€ ì—†ëŠ” í…ŒìŠ¤íŠ¸ë§Œ
pytest -m "integration"  # integration ë§ˆì»¤ê°€ ìˆëŠ” í…ŒìŠ¤íŠ¸ë§Œ
```

#### ì»¤ë²„ë¦¬ì§€ í¬í•¨ ì‹¤í–‰
```bash
# ì»¤ë²„ë¦¬ì§€ ì¸¡ì •
pytest --cov=src tests/

# HTML ë¦¬í¬íŠ¸ ìƒì„±
pytest --cov=src --cov-report=html tests/

# ì»¤ë²„ë¦¬ì§€ ì„ê³„ê°’ ì„¤ì •
pytest --cov=src --cov-fail-under=80 tests/
```

#### ë³‘ë ¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# pytest-xdist ì„¤ì¹˜
pip install pytest-xdist

# ë³‘ë ¬ ì‹¤í–‰
pytest -n auto  # CPU ì½”ì–´ ìˆ˜ë§Œí¼
pytest -n 4     # 4ê°œ í”„ë¡œì„¸ìŠ¤
```

### í…ŒìŠ¤íŠ¸ ì„¤ì •

#### pytest.ini
```ini
[tool:pytest]
minversion = 6.0
addopts =
    -ra
    --strict-markers
    --strict-config
    --cov=src
    --cov-report=term-missing
    --cov-report=html
    --cov-fail-under=80
testpaths = tests
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    integration: marks tests as integration tests
    e2e: marks tests as end-to-end tests
    benchmark: marks tests as performance benchmarks
```

#### conftest.py
```python
# tests/conftest.py
import pytest
import asyncio
from unittest.mock import Mock

@pytest.fixture(scope="session")
def event_loop():
    """ì„¸ì…˜ ë²”ìœ„ ì´ë²¤íŠ¸ ë£¨í”„"""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest.fixture
def mock_api_key():
    """í…ŒìŠ¤íŠ¸ìš© API í‚¤"""
    return "test-api-key-for-testing"

@pytest.fixture
def sample_template_data():
    """ìƒ˜í”Œ í…œí”Œë¦¿ ë°ì´í„°"""
    return {
        "text": "ì•ˆë…•í•˜ì„¸ìš” #{ìˆ˜ì‹ ìëª…}ë‹˜...",
        "variables": ["ìˆ˜ì‹ ìëª…", "ìƒí’ˆëª…"],
        "metadata": {
            "business_type": "êµìœ¡",
            "approval_status": "approved"
        }
    }

@pytest.fixture
def mock_vector_store():
    """ëª¨í‚¹ëœ ë²¡í„° ìŠ¤í† ì–´"""
    mock_store = Mock()
    mock_store.search_relevant_policies.return_value = [
        {
            "content": "ì •ì±… ë‚´ìš©",
            "metadata": {"source": "test.md"},
            "relevance_score": 0.9
        }
    ]
    return mock_store
```

### CI/CD í†µí•©

#### GitHub Actions ì›Œí¬í”Œë¡œìš°
```yaml
# .github/workflows/test.yml
name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.11, 3.12]

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Run unit tests
      run: |
        pytest tests/unit/ -v

    - name: Run integration tests
      run: |
        pytest tests/integration/ -v
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

    - name: Run E2E tests
      run: |
        pytest tests/e2e/ -v --timeout=300
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
```

### í…ŒìŠ¤íŠ¸ ë¦¬í¬íŒ…

#### HTML ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸
```bash
# ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸ ìƒì„±
pytest --cov=src --cov-report=html tests/

# ë¦¬í¬íŠ¸ í™•ì¸
open htmlcov/index.html  # macOS
start htmlcov/index.html  # Windows
```

#### JUnit XML ë¦¬í¬íŠ¸
```bash
# JUnit í˜•ì‹ ë¦¬í¬íŠ¸ ìƒì„±
pytest --junitxml=test-results.xml tests/
```

#### ì„±ëŠ¥ ë¦¬í¬íŠ¸
```bash
# ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸
pytest --benchmark-only --benchmark-save=baseline tests/
pytest --benchmark-compare=baseline tests/
```

---

**ğŸ“… ì‘ì„±ì¼**: 2024ë…„ 9ì›” 19ì¼
**âœï¸ ì‘ì„±ì**: Final Team 3 AI
**ğŸ“„ ë¬¸ì„œ ë²„ì „**: 1.0
**ğŸ”„ ìµœì¢… ìˆ˜ì •**: 2024ë…„ 9ì›” 19ì¼