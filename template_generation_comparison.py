#!/usr/bin/env python3
"""
ì‹¤ì œ í…œí”Œë¦¿ ìƒì„± ê²°ê³¼ ë¹„êµ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
Claude vs OpenAI ëª¨ë¸ë³„ í…œí”Œë¦¿ ìƒì„± í’ˆì§ˆ ì‹œê°ì  ë¹„êµ
"""

import json
import os
from typing import Dict, List
from datetime import datetime

def extract_template_responses():
    """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ì—ì„œ í…œí”Œë¦¿ ìƒì„± ì‘ë‹µ ì¶”ì¶œ"""

    # ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ íŒŒì¼ ì½ê¸°
    result_file = "claude_vs_openai_comparison_20250920_092319.json"

    with open(result_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # í…œí”Œë¦¿ ìƒì„± ê²°ê³¼ ì¶”ì¶œ
    template_comparisons = {}

    for model_key, model_data in data['models_tested'].items():
        if 'test_results' in model_data:
            for test in model_data['test_results']:
                if test['success']:
                    test_name = test['test_name']

                    if test_name not in template_comparisons:
                        template_comparisons[test_name] = {}

                    # ëª¨ë¸ëª… ì •ë¦¬
                    provider = model_data['provider']
                    model_name = model_data['model']
                    clean_name = f"{provider}_{model_name.split('-')[-1]}"

                    template_comparisons[test_name][clean_name] = {
                        'response_time': test['response_time'],
                        'tokens': test['total_tokens'],
                        'quality': test['quality_score'],
                        'template': test['response_text']
                    }

    return template_comparisons

def create_comparison_document():
    """í…œí”Œë¦¿ ìƒì„± ë¹„êµ ë¬¸ì„œ ìƒì„±"""

    template_data = extract_template_responses()

    # ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„±
    md_content = """# ğŸ” ì‹¤ì œ í…œí”Œë¦¿ ìƒì„± ê²°ê³¼ ë¹„êµ ë¶„ì„

## ğŸ“‹ ë¬¸ì„œ ê°œìš”

ë³¸ ë¬¸ì„œëŠ” ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ Claudeì™€ OpenAI ëª¨ë¸ë“¤ì´ ì‹¤ì œë¡œ ìƒì„±í•œ í…œí”Œë¦¿ì„ ì§ì ‘ ë¹„êµí•˜ì—¬ ê° ëª¨ë¸ì˜ íŠ¹ì§•ê³¼ ì°¨ì´ì ì„ ë¶„ì„í•©ë‹ˆë‹¤.

**í…ŒìŠ¤íŠ¸ ì¼ì‹œ**: 2025ë…„ 9ì›” 20ì¼
**ë¹„êµ ëª¨ë¸**: Claude 3.5 Haiku/Sonnet, GPT-4o/4o-mini
**í‰ê°€ í•­ëª©**: í•œêµ­ì–´ í’ˆì§ˆ, êµ¬ì¡°í™”, ì •ì±… ì¤€ìˆ˜, ì°½ì˜ì„±

---

"""

    # ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë³„ ë¹„êµ
    for i, (test_name, models) in enumerate(template_data.items(), 1):

        md_content += f"""## {i}. {test_name}

### ğŸ“Š ì„±ëŠ¥ ìš”ì•½

| ëª¨ë¸ | ì‘ë‹µì‹œê°„ | í† í°ìˆ˜ | í’ˆì§ˆì ìˆ˜ |
|------|----------|--------|----------|
"""

        # ì„±ëŠ¥ í‘œ ìƒì„±
        for model, data in models.items():
            md_content += f"| {model} | {data['response_time']:.2f}ì´ˆ | {data['tokens']} | {data['quality']}/5 |\n"

        md_content += "\n### ğŸ’¬ ì‹¤ì œ ìƒì„± ê²°ê³¼ ë¹„êµ\n\n"

        # ê° ëª¨ë¸ì˜ í…œí”Œë¦¿ ê²°ê³¼
        for model, data in models.items():
            md_content += f"""#### {model}

```
{data['template']}
```

**ë¶„ì„**:
- ì‘ë‹µì‹œê°„: {data['response_time']:.2f}ì´ˆ
- í† í° ì‚¬ìš©: {data['tokens']}ê°œ
- í’ˆì§ˆ ì ìˆ˜: {data['quality']}/5

---

"""

        # ëª¨ë¸ë³„ ë¹„êµ ë¶„ì„
        md_content += f"""### ğŸ” ëª¨ë¸ë³„ íŠ¹ì§• ë¶„ì„

#### Claude ëª¨ë¸ì˜ íŠ¹ì§•:
"""
        claude_models = [k for k in models.keys() if 'Anthropic' in k]
        for model in claude_models:
            template = models[model]['template']
            md_content += f"""
**{model}**:
- í•œêµ­ì–´ ì¡´ëŒ“ë§: {'ìš°ìˆ˜' if 'ìŠµë‹ˆë‹¤' in template or 'ì„¸ìš”' in template else 'ë³´í†µ'}
- ë³€ìˆ˜ ì‚¬ìš©: {'ì ì ˆ' if '#{' in template else 'ì—†ìŒ'}
- êµ¬ì¡°í™”: {'ì²´ê³„ì ' if chr(10)+chr(10) in template else 'ë‹¨ìˆœ'}
- ê¸¸ì´: {len(template)}ì
"""

        md_content += f"""
#### OpenAI ëª¨ë¸ì˜ íŠ¹ì§•:
"""
        openai_models = [k for k in models.keys() if 'OpenAI' in k]
        for model in openai_models:
            template = models[model]['template']
            md_content += f"""
**{model}**:
- í•œêµ­ì–´ ì¡´ëŒ“ë§: {'ìš°ìˆ˜' if 'ìŠµë‹ˆë‹¤' in template or 'ì„¸ìš”' in template else 'ë³´í†µ'}
- ë³€ìˆ˜ ì‚¬ìš©: {'ì ì ˆ' if '#{' in template or '{' in template else 'ì—†ìŒ'}
- êµ¬ì¡°í™”: {'ì²´ê³„ì ' if chr(10)+chr(10) in template else 'ë‹¨ìˆœ'}
- ê¸¸ì´: {len(template)}ì
"""

        md_content += "\n---\n\n"

    # ì¢…í•© ë¶„ì„ ì¶”ê°€
    md_content += """## ğŸ† ì¢…í•© ë¶„ì„ ë° ê²°ë¡ 

### í•œêµ­ì–´ í…œí”Œë¦¿ ìƒì„± ì¢…í•© í‰ê°€

#### 1. ì–¸ì–´ì  ìì—°ìŠ¤ëŸ¬ì›€
"""

    # ëª¨ë¸ë³„ íŠ¹ì§• ìš”ì•½
    all_models = set()
    for models in template_data.values():
        all_models.update(models.keys())

    for model in sorted(all_models):
        total_quality = 0
        total_tests = 0
        total_time = 0
        total_tokens = 0

        for test_models in template_data.values():
            if model in test_models:
                total_quality += test_models[model]['quality']
                total_time += test_models[model]['response_time']
                total_tokens += test_models[model]['tokens']
                total_tests += 1

        if total_tests > 0:
            avg_quality = total_quality / total_tests
            avg_time = total_time / total_tests
            avg_tokens = total_tokens / total_tests

            md_content += f"""
**{model}**:
- í‰ê·  í’ˆì§ˆ: {avg_quality:.2f}/5
- í‰ê·  ì‘ë‹µì‹œê°„: {avg_time:.2f}ì´ˆ
- í‰ê·  í† í°: {avg_tokens:.0f}ê°œ
- íŠ¹ì§•: {get_model_characteristics(model, template_data)}
"""

    md_content += """
### ìµœì¢… ê¶Œì¥ì‚¬í•­

#### ğŸ¥‡ í…œí”Œë¦¿ ìƒì„± ìµœì  ëª¨ë¸ ìˆœìœ„

1. **Claude 3.5 Haiku**: ë¹ ë¥¸ ì†ë„ + ìš°ìˆ˜í•œ í•œêµ­ì–´ í’ˆì§ˆ
2. **GPT-4o**: ë†’ì€ í’ˆì§ˆ + ë‹¤ì–‘í•œ í‘œí˜„
3. **Claude 3.5 Sonnet**: ì •í™•ì„± + ìƒì„¸í•œ ë¶„ì„
4. **GPT-4o-mini**: íš¨ìœ¨ì„± + ì•ˆì •ì„±

#### ğŸ’¡ ìƒí™©ë³„ ì¶”ì²œ

- **ëŒ€ëŸ‰ í…œí”Œë¦¿ ìƒì„±**: Claude 3.5 Haiku
- **ì°½ì˜ì  ë§ˆì¼€íŒ…**: GPT-4o
- **ì •ì±… ì¤€ìˆ˜ ì¤‘ì‹œ**: Claude 3.5 Sonnet
- **ë¹„ìš© íš¨ìœ¨ì„±**: GPT-4o-mini

---

**ìƒì„±ì¼**: 2025ë…„ 9ì›” 20ì¼
**ë°ì´í„° ê¸°ì¤€**: ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼
**ë¶„ì„ ë°©ë²•**: ë™ì¼ ì§ˆë¬¸ 4ê°œ ëª¨ë¸ ë¹„êµ
"""

    return md_content

def get_model_characteristics(model_name: str, template_data: Dict) -> str:
    """ëª¨ë¸ë³„ íŠ¹ì§• ë¶„ì„"""

    characteristics = []

    # ëª¨ë¸ë³„ í…œí”Œë¦¿ ìƒ˜í”Œ ë¶„ì„
    templates = []
    for test_models in template_data.values():
        if model_name in test_models:
            templates.append(test_models[model_name]['template'])

    if not templates:
        return "ë°ì´í„° ë¶€ì¡±"

    # íŠ¹ì§• ë¶„ì„
    avg_length = sum(len(t) for t in templates) / len(templates)
    formal_count = sum(1 for t in templates if 'ìŠµë‹ˆë‹¤' in t or 'ì„¸ìš”' in t)
    variable_count = sum(1 for t in templates if '#{' in t or '{' in t)
    structured_count = sum(1 for t in templates if '\n\n' in t)

    if avg_length > 300:
        characteristics.append("ìƒì„¸í•œ ì„¤ëª…")
    elif avg_length < 150:
        characteristics.append("ê°„ê²°í•œ í‘œí˜„")

    if formal_count / len(templates) > 0.8:
        characteristics.append("ì •ì¤‘í•œ ì¡´ëŒ“ë§")

    if variable_count / len(templates) > 0.7:
        characteristics.append("ì ì ˆí•œ ë³€ìˆ˜ í™œìš©")

    if structured_count / len(templates) > 0.5:
        characteristics.append("ì²´ê³„ì  êµ¬ì¡°")

    if 'Claude' in model_name:
        characteristics.append("í•œêµ­ì–´ íŠ¹í™”")
    elif 'OpenAI' in model_name:
        characteristics.append("ë‹¤ì–‘í•œ í‘œí˜„ë ¥")

    return ", ".join(characteristics) if characteristics else "í‘œì¤€ì "

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("í…œí”Œë¦¿ ìƒì„± ë¹„êµ ë¶„ì„ ë¬¸ì„œ ìƒì„± ì¤‘...")

    try:
        # ë¹„êµ ë¬¸ì„œ ìƒì„±
        content = create_comparison_document()

        # íŒŒì¼ ì €ì¥
        filename = "docs/p14_template_generation_comparison.md"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)

        print(f"âœ… ë¹„êµ ë¶„ì„ ë¬¸ì„œ ìƒì„± ì™„ë£Œ: {filename}")

        # ê°„ë‹¨í•œ ìš”ì•½ ì¶œë ¥
        template_data = extract_template_responses()
        print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
        print(f"- ë¹„êµëœ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(template_data)}ê°œ")
        print(f"- ë¶„ì„ëœ ëª¨ë¸: 4ê°œ (Claude 2ê°œ, OpenAI 2ê°œ)")
        print(f"- ìƒì„±ëœ í…œí”Œë¦¿: {len(template_data) * 4}ê°œ")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()